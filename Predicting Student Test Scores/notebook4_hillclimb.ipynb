{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OOF Stacking + Hill Climb (Educational)\n",
        "This notebook blends many community OOF predictions. We:  ",
        "1) load OOF/sub predictions,  ",
        "2) optionally hill-climb for a weighted blend,  ",
        "3) fit a RidgeCV meta-model to finalize the stack.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install hillclimbers (one-time per environment)\n",
        "!pip install hillclimbers -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import hashlib\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from hillclimbers import climb_hill, partial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 0) CONFIGURATION\n",
        "# ==========================================\n",
        "# test_req=True makes the run faster by sampling; use False for final blending\n",
        "test_req = False\n",
        "skip_hillclimb = False\n",
        "\n",
        "BASE_DIR = r\"C:\\Users\\james\\OneDrive\\Documents\\GitHub\\Kaggle-Competitions\\Predicting Student Test Scores\"\n",
        "OOF_DIR = r\"C:\\Users\\james\\OneDrive\\Documents\\GitHub\\Kaggle-Competitions\\Predicting Student Test Scores\\OOF_PREDS\"\n",
        "\n",
        "TARGET = 'exam_score'\n",
        "TRAIN_PATH = os.path.join(BASE_DIR, 'train.csv')\n",
        "SAMPLE_SUB_PATH = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
        "\n",
        "print('Base dir:', BASE_DIR)\n",
        "print('OOF dir:', OOF_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 1) LOAD OOF + SUB FILES\n",
        "# ==========================================\n",
        "# Expected naming: modelname_oof.csv and modelname_sub.csv\n",
        "oof_files = sorted(glob.glob(os.path.join(OOF_DIR, '*_oof.csv')))\n",
        "if not oof_files:\n",
        "    raise FileNotFoundError('No *_oof.csv files found. Check OOF_DIR or filenames.')\n",
        "\n",
        "sub_files = [f.replace('_oof.csv', '_sub.csv') for f in oof_files]\n",
        "model_names = [os.path.basename(f).replace('_oof.csv', '') for f in oof_files]\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "y_true = train_df[TARGET].values\n",
        "\n",
        "print(f'Loaded {len(model_names)} models')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 2) DEDUPLICATE IDENTICAL SUBMISSIONS\n",
        "# ==========================================\n",
        "# Some community submissions are identical; remove duplicates to reduce noise.\n",
        "unique_subs = {}\n",
        "indices_to_keep = []\n",
        "\n",
        "for i, (s_file, name) in enumerate(zip(sub_files, model_names)):\n",
        "    temp_sub = pd.read_csv(s_file)[TARGET].values\n",
        "    sub_hash = hashlib.md5(temp_sub.tobytes()).hexdigest()\n",
        "    if sub_hash not in unique_subs:\n",
        "        unique_subs[sub_hash] = name\n",
        "        indices_to_keep.append(i)\n",
        "    else:\n",
        "        print(f'?? Dropping duplicate: {name}')\n",
        "\n",
        "oof_files = [oof_files[i] for i in indices_to_keep]\n",
        "sub_files = [sub_files[i] for i in indices_to_keep]\n",
        "model_names = [model_names[i] for i in indices_to_keep]\n",
        "\n",
        "print(f'Models after dedup: {len(model_names)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3) BUILD OOF/SUB MATRICES\n",
        "# ==========================================\n",
        "# Each column = one model's predictions\n",
        "oofs = np.stack([pd.read_csv(f)[TARGET].values for f in oof_files], axis=1)\n",
        "subs = np.stack([pd.read_csv(f)[TARGET].values for f in sub_files], axis=1)\n",
        "\n",
        "df_oof = pd.DataFrame(oofs, columns=model_names)\n",
        "df_sub = pd.DataFrame(subs, columns=model_names)\n",
        "\n",
        "print('OOF shape:', df_oof.shape)\n",
        "print('SUB shape:', df_sub.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 4) OPTIONAL: HILL CLIMBING BLEND\n",
        "# ==========================================\n",
        "# Hill climbing finds weights that minimize RMSE on OOFs.\n",
        "hc_precision = 0.01 if test_req else 0.001\n",
        "hc_negative = False if test_req else True\n",
        "\n",
        "if test_req:\n",
        "    np.random.seed(42)\n",
        "    sample_idx = np.random.choice(len(train_df), size=int(len(train_df) * 0.2), replace=False)\n",
        "    hc_train = train_df.iloc[sample_idx].reset_index(drop=True)\n",
        "    hc_oof = df_oof.iloc[sample_idx].reset_index(drop=True)\n",
        "    y_stack = hc_train[TARGET].values\n",
        "    print(f'Test mode: using {len(hc_train)} rows')\n",
        "else:\n",
        "    hc_train = train_df\n",
        "    hc_oof = df_oof\n",
        "    y_stack = y_true\n",
        "\n",
        "if not skip_hillclimb:\n",
        "    print('Running hill climb...')\n",
        "    hc_test, hc_oof_blend = climb_hill(\n",
        "        train=hc_train,\n",
        "        target=TARGET,\n",
        "        objective='minimize',\n",
        "        eval_metric=partial(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False)),\n",
        "        oof_pred_df=hc_oof,\n",
        "        test_pred_df=df_sub,\n",
        "        precision=hc_precision,\n",
        "        negative_weights=hc_negative,\n",
        "        return_oof_preds=True\n",
        "    )\n",
        "    # Use the blended output as a single stacking feature\n",
        "    X_train = hc_oof_blend.reshape(-1, 1)\n",
        "    X_test = hc_test.reshape(-1, 1)\n",
        "else:\n",
        "    print('Skipping hill climb: using all model OOFs for stacking')\n",
        "    X_train = oofs\n",
        "    X_test = subs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 5) RIDGE CV STACKING\n",
        "# ==========================================\n",
        "# RidgeCV finds the best linear combination of the input predictions.\n",
        "kf_splits = 3 if test_req else 10\n",
        "kf = KFold(n_splits=kf_splits, shuffle=True, random_state=42)\n",
        "alphas = np.logspace(-2, 7, 50)\n",
        "\n",
        "oof_final = np.zeros(len(y_stack))\n",
        "sub_final = np.zeros(X_test.shape[0])\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(kf.split(X_train)):\n",
        "    X_tr, y_tr = X_train[tr_idx], y_stack[tr_idx]\n",
        "    X_va, y_va = X_train[va_idx], y_stack[va_idx]\n",
        "\n",
        "    model = RidgeCV(alphas=alphas, scoring='neg_root_mean_squared_error')\n",
        "    model.fit(X_tr, y_tr)\n",
        "\n",
        "    oof_final[va_idx] = model.predict(X_va)\n",
        "    sub_final += model.predict(X_test) / kf_splits\n",
        "    print(f'Fold {fold+1}/{kf_splits} complete. Alpha: {model.alpha_:.4f}')\n",
        "\n",
        "rmse = mean_squared_error(y_stack, oof_final, squared=False)\n",
        "print(f'FINAL RMSE: {rmse:.6f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 6) SAVE SUBMISSION\n",
        "# ==========================================\n",
        "sub_template = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "sub_template[TARGET] = sub_final\n",
        "out_path = os.path.join(BASE_DIR, f'submission_rmse_{rmse:.6f}.csv')\n",
        "sub_template.to_csv(out_path, index=False)\n",
        "print('Saved:', out_path)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}